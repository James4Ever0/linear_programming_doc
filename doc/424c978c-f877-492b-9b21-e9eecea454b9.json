{
    "summary": "This code defines API endpoints for asynchronous tasks, manages pending tasks using a global lock and task list, and runs a uvicorn web application on specified port.",
    "details": [
        {
            "comment": "```python\n# Import necessary libraries and modules (FastAPI, time, test_server_client_configs)\n# Define GLOBAL_TASK_COUNT variable\n# Set limit to max running time per task using datetime and pydantic's BaseModel for parsing data\n# Function get_current_time_string() returns the current time string without microseconds\n# Mock_calculation function mocks heavy system optimization calculation with optional sleep time\n# Create FastAPI instance and define routes/endpoints (not shown)\n```",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/test_server.py\":0-40",
            "content": "from fastapi import FastAPI\nimport time\nfrom test_server_client_configs import *\nGLOBAL_TASK_COUNT = 0\nimport datetime\n# of course we will set limit to max running time per task\nfrom pydantic import BaseModel\nclass DataModel(BaseModel): # use this to parse the dict passed in later.\n    data: str\ndef get_current_time_string():\n    time_string = \" \".join(datetime.datetime.now().isoformat().split(\".\")[0].split(\"T\"))\n    return time_string\ndef mock_calculation(data: DataModel, sleep_time: float = 20):\n    \"\"\"\n    Mocking the heavy calculation of system optimization.\n    Args:\n        sleep_time (float): the duration of our fake task, in seconds\n    \"\"\"\n    print(f\"TIME: {get_current_time_string()}\")\n    print(f\"DATA RECEIVED: {len(str(data))}\")\n    print(f\"CALCULATING! TOTAL TASK #{GLOBAL_TASK_COUNT}\")\n    time.sleep(sleep_time)\n    print(f\"TOTAL TASK #{GLOBAL_TASK_COUNT}. DONE!\")\n    return \"CALCULATED RESULT\"  # fake though.\napp = FastAPI()\n# where is the port?\n# create some context manager? sure?\n# could there be multiple requests? use lock please?"
        },
        {
            "comment": "The code defines a lock for thread synchronization, functions to add or remove a task and limit the maximum number of tasks. The `trick_or_treat` function adds and removes tasks, performs a calculation using mock data, and returns the result. A POST endpoint handles requests to upload graphs. The `execute_and_append_result_to_dict` function executes tasks, appends results to a dictionary, and generates unique IDs for tasks.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/test_server.py\":41-90",
            "content": "import threading\nLOCK = threading.Lock()\ndef add_one_task():\n    global GLOBAL_TASK_COUNT, LOCK, MAX_TASK_COUNT\n    with LOCK:\n        if GLOBAL_TASK_COUNT < MAX_TASK_COUNT:\n            GLOBAL_TASK_COUNT += 1\n            return True\n    return False\ndef remove_one_task():\n    global GLOBAL_TASK_COUNT, LOCK\n    with LOCK:\n        if GLOBAL_TASK_COUNT >= 0 and GLOBAL_TASK_COUNT <= MAX_TASK_COUNT:\n            GLOBAL_TASK_COUNT -= 1\n            return True\n    return False\ndef trick_or_treat(data: DataModel):\n    global server_error_code\n    if add_one_task():\n        result = mock_calculation(data)  # you should put error code here. no exception?\n        remove_one_task()\n        return result\n    return server_error_code.MAX_TASK_LIMIT\n# import json\n@app.post(f\"/{endpoint_suffix.UPLOAD_GRAPH}\")\ndef run_sync(info: dict):\n    print(\"INFO:\",info)\n    # data = json.loads(info.data)\n    data = DataModel(**info)\n    return trick_or_treat(data) # need a dictionary.\nRESULT_DICT = {}\nTASK_LIST = []\nimport uuid\ndef execute_and_append_result_to_dict(unique_id: str, data: DataModel):"
        },
        {
            "comment": "This code defines API endpoints for asynchronous task assignment and result retrieval. It utilizes a global `RESULT_DICT` to store task results and a `TASK_LIST` to keep track of pending tasks. Tasks are executed in separate threads, and the API returns unique IDs or error codes accordingly.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/test_server.py\":91-121",
            "content": "    global RESULT_DICT, TASK_LIST\n    print(f\"ASYNC TASK ASSIGNED: {unique_id}\")\n    result = mock_calculation(data)\n    RESULT_DICT.update({unique_id: result})\n    TASK_LIST.remove(unique_id)\n@app.post(f\"/{endpoint_suffix.UPLOAD_GRAPH_ASYNC}\")\ndef run_async(info: dict):  # how do you do it async? redis cache?\n    # data = info\n    # data = json.loads(info.data)\n    data = DataModel(**info)\n    # cause DataModel as type hint won't get you a full dict.\n    # you have to do parsing later.\n    if add_one_task():\n        unique_id = str(uuid.uuid4())\n        TASK_LIST.append(unique_id)\n        threading.Thread(\n            target=execute_and_append_result_to_dict, args=(unique_id, data)\n        ).start()  # not \"run\"\n        return unique_id\n    return server_error_code.MAX_TASK_LIMIT\n@app.get(f\"/{endpoint_suffix.CHECK_RESULT_ASYNC}\")\ndef get_result_async(unique_id: str):\n    print(\"GETTING RESULT:\", unique_id)\n    print(\"RESULT_DICT:\", RESULT_DICT)\n    print(\"TASK_LIST:\", TASK_LIST)\n    return RESULT_DICT.get(\n        unique_id,"
        },
        {
            "comment": "This code checks if a unique ID exists in the TASK_LIST. If it does, it returns server_error_code.PENDING. Otherwise, it returns server_error_code.NOTHING, and then runs the uvicorn web application on the specified port.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/test_server.py\":122-130",
            "content": "        server_error_code.PENDING\n        if unique_id in TASK_LIST\n        else server_error_code.NOTHING,\n    )\nimport uvicorn\nuvicorn.run(app, port=port)"
        }
    ]
}