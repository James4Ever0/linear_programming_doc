{
    "summary": "The code reads Excel data, generates JSON format, handles planning results and filters irrelevant terms for microgrid simulation. It processes results, ensures unique device definitions, writes to a JSON file, and renders templates for formatting in the microgrid base.",
    "details": [
        {
            "comment": "This code imports necessary modules, defines variables for file paths, and initializes a dictionary of inputs and outputs for a Makefile. The code aims to parse an Excel file, generate code from templates, and output the result in JSON format. Additionally, it handles planning results by creating a separate file with a specific naming convention.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":0-40",
            "content": "from log_utils import logger_print\nexcel_path = \"\u8bbe\u5907\u4fe1\u606f\u5e93\u5404\u53c2\u6570_10_24.xlsx\"\n# excel_path = \"\u8bbe\u5907\u4fe1\u606f\u5e93\u5404\u53c2\u6570_10_12.xlsx\"\n# excel_path = \"\u8bbe\u5907\u4fe1\u606f\u5e93\u5404\u53c2\u6570.xlsx\"\nfrom lib_parse_params import repair_excel\nrepair_excel(excel_path)\nfrom jinja_utils import code_and_template_path, load_render_and_format\nimport rich\nimport re\nfrom constants import *\ncode_path, template_path = code_and_template_path(\"export_format_validate\")\ncode_unit_path, template_unit_path = code_and_template_path(\n    \"export_format_units\"\n)  # TODO: mark this as dependency as \"ies_optim.py\"\n# you may also need to render some other code to avoid circular importing issues.\n\u8bbe\u8ba1\u89c4\u5212\u7ed3\u679c\u8f93\u51faCSV = \"\u8bbe\u5907\u4fe1\u606f\u5e93\u5404\u53c2\u6570-\u89c4\u5212\u65b9\u6848\u53ca\u8be6\u60c5.csv\"  # parse this thing first.\noutput_path = \"export_format.json\"\nplanning_output_path = f\"planning_{output_path}\"\nMAKEFILE = dict(\n    inputs=[template_path, template_unit_path, excel_path, \u8bbe\u8ba1\u89c4\u5212\u7ed3\u679c\u8f93\u51faCSV],\n    outputs=[output_path, code_path, code_unit_path, planning_output_path],\n    args=[],\n)\nimport json\n# from os import name\nimport pandas\n# --------------------------- #"
        },
        {
            "comment": "This code reads the design planning export data format and prepares to store it. It checks for specific patterns in the data, such as \"\u65b9\u6848\" followed by a four-character string, and extracts relevant sub-schemas. It also defines a set of terms to remove before saving to disk. The code uses regular expressions (regex) to identify and filter these terms.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":41-78",
            "content": "#   \u8bbe\u8ba1\u89c4\u5212\u5bfc\u51fa\u6570\u636e\u683c\u5f0f\u51c6\u5907    #\n# --------------------------- #\n\u8bbe\u8ba1\u89c4\u5212\u7ed3\u679c\u8f93\u51fa\u683c\u5f0f\u8868\u683c = pandas.read_csv(\n    \u8bbe\u8ba1\u89c4\u5212\u7ed3\u679c\u8f93\u51faCSV, on_bad_lines=\"warn\", header=None\n)  # you can ignore bad lines.\n# logger_print(\u8bbe\u8ba1\u89c4\u5212\u7ed3\u679c\u8f93\u51fa\u683c\u5f0f\u8868\u683c)\n# breakpoint()\nsubSchemas = []\n# breakpoint()\nfor colIndex in (\u8bbe\u8ba1\u89c4\u5212T := \u8bbe\u8ba1\u89c4\u5212\u7ed3\u679c\u8f93\u51fa\u683c\u5f0f\u8868\u683c.T):\n    firstElem = (col := \u8bbe\u8ba1\u89c4\u5212T[colIndex].to_list())[0]\n    if (\n        isinstance(firstElem, str)\n        and not isinstance(col[1], str)\n        and len(firstElem) == 4\n        and firstElem.startswith(\"\u65b9\u6848\")\n    ):\n        # logger_print(firstElem)\n        # breakpoint()\n        subSchemas.append((firstElem, colIndex))\nplanningResultSchema = {schemaName: {} for schemaName, _ in subSchemas}\nfrom unit_utils import unitParserWrapper\n# need to remove few terms before saving to disk.\nremoveTermRegexes = {\n    \"\u65b9\u6848\u5217\u8868\": [r\"\u5e74\u5e73\u5747.+\", \"\u65b9\u6848\u540d\u79f0\"],  # use non-greedy modifier (backtracking)\n    \"\u65b9\u6848\u8be6\u60c5\": [\"\u80fd\u6e90\u6d88\u8017\u8d39\u7528\", r\"\u5e74.+?\u6536\u5165\", \"\u51fa\u529b\u66f2\u7ebf\"],\n}\nhitRecords = {k: {e: False} for k, v in removeTermRegexes.items() for e in v}\nfrom typing import List\ndef checkIfMatchAListOfRegexes(term: str, regexList: List[str], key: str):"
        },
        {
            "comment": "The code defines a function to get the schema type based on the header and unit, iterates over subSchemas, and checks for any NaN values. The code uses regex matching to determine if a term matches specific patterns, and returns True or False accordingly. It also demonstrates assignment expressions in Python 3.10 for simplifying subscript assignments.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":79-111",
            "content": "    for regex in regexList:\n        if re.match(regex, term):\n            hitRecords[key][term] = True\n            return True\n    return False\ndef getSchemaType(schemaHeader, schemaHeaderUnit):\n    if schemaHeaderUnit:\n        return \"float\"\n    else:\n        if schemaHeader in [\"\u6570\u91cf\"]:\n            return \"int\"\n        elif schemaHeader in [\"\u5e73\u5747\u6548\u7387_\u5e73\u5747COP\"]:\n            return \"float\"\n        else:\n            return \"str\"\nfor schemaName, index in subSchemas:  # why we have nan here?\n    regexList = removeTermRegexes[schemaName]\n    # Assignment expressions within a subscript are supported only in Python 3.10 and newer\n    schemaHeaderIndex = index + 1\n    schemaHeaders = \u8bbe\u8ba1\u89c4\u5212T[schemaHeaderIndex].to_list()\n    # schemaHeaders = \u8bbe\u8ba1\u89c4\u5212T[schemaHeaderIndex := index + 1].to_list()\n    # logger_print(schemaHeaders)\n    # breakpoint()\n    englishSchemaHeaderIndex = schemaHeaderIndex + 2\n    englishSchemaHeaders = \u8bbe\u8ba1\u89c4\u5212T[\n        englishSchemaHeaderIndex\n        # englishSchemaHeaderIndex := schemaHeaderIndex + 2\n    ].to_list()"
        },
        {
            "comment": "This code segment appears to be filtering and processing data headers based on regex matches. It removes NaN values, replaces forward slashes with underscores, and trims the data for generating code. The code also checks if all regexes have hits without any misses, logging errors if necessary.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":112-138",
            "content": "    # breakpoint()\n    # \u53bb\u9664\u4e86\u81ea\u6765\u6c34\u6d88\u8017\n    remove_isna = lambda it: filter(lambda e: not pandas.isna(e), it)\n    for schemaHeader, englishSchemaHeader in zip(\n        remove_isna(schemaHeaders), remove_isna(englishSchemaHeaders)\n    ):\n        schemaHeader = schemaHeader.replace(\"/\", \"_\")  # for code generation\n        strippedSchemaHeader, schemaHeaderUnit = unitParserWrapper(schemaHeader)\n        if checkIfMatchAListOfRegexes(strippedSchemaHeader, regexList, schemaName):\n            logger_print(\"SKIPPING:\", strippedSchemaHeader)\n            continue\n        planningResultSchema[schemaName].update(\n            {\n                strippedSchemaHeader: {\n                    \"unit\": schemaHeaderUnit,  # could be \"None\"\n                    \"englishName\": englishSchemaHeader,\n                    \"type\": getSchemaType(schemaHeader, schemaHeaderUnit),\n                }\n            }\n        )\n# check if all regexes have hits.\nerrors = []\nfor k, v in hitRecords.items():\n    for e in v:\n        if e is False:\n            errors.append(f\"Error: regex {e.__repr__()} with no match!\")"
        },
        {
            "comment": "Code reads an excel sheet, checks for empty cells, and stores data in a dictionary with keys from non-empty first cell values and appends device names to the dictionary's last key's \"devices\" list. Saves the planningResultSchema to a file using json.dumps().",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":140-180",
            "content": "if errors:\n    raise Exception(\"\\n\".join(errors))\nlogger_print(planningResultSchema)\n# breakpoint()\n# store this to file. remember to mention this file in Makefile. automation tools like \"dyndep\" in ninja, or \"submake\" can be used.\nwith open(planning_output_path, \"w+\") as f:\n    f.write(json.dumps(planningResultSchema, indent=4, ensure_ascii=False))\n# -------------------------- #\ntable_name = \"\u4eff\u771f\u7ed3\u679c\"\ntable = pandas.read_excel(excel_path, sheet_name=table_name, header=None)\n# logger_print(table)\ndef is_empty(elem):\n    if type(elem) is str:\n        return elem.strip() == \"\"\n    else:\n        return True\ntrough = 0\ndata = {}\nfor i, r in table.iterrows():\n    rlist = [(e.strip() if type(e) == str else \"\") for e in r.tolist()]\n    first_elem, second_elem = rlist[0], rlist[1]\n    if is_empty(first_elem):\n        trough = 0\n    elif not is_empty(first_elem) and is_empty(second_elem):\n        if trough == 0:\n            trough = 1\n            key = first_elem\n        elif trough == 2:\n            device = rlist[0]\n            data[key][-1][\"devices\"].append(device)"
        },
        {
            "comment": "This code is parsing and processing a list of elements, breaking it into headings and devices, and storing the data in a dictionary. It also performs unit conversion using functions from the unit_utils module. The revmap dictionary contains mappings for converting units between different categories.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":181-225",
            "content": "    elif not is_empty(first_elem) and not is_empty(second_elem):\n        # breakpoint()\n        last_empty_index = len(rlist)\n        try:\n            last_empty_index = rlist.index(\"\")\n        except:\n            pass\n        headings = rlist[:last_empty_index]\n        trough = 2\n        data[key] = data.get(key, []) + [{\"headings\": headings, \"devices\": []}]\n# need processing.\nlogger_print(data)\nlogger_print(\"writing to:\", output_path)\nnew_data = {k: {} for k in data.keys()}\nrevmap = {\n    \"one\": [\"\u5e73\u5747\u6548\u7387/\u5e73\u5747COP\", \"\u8bbe\u5907\u53f0\u6570\", \"\u65f6\u95f4\"],\n    # \"\u4e07\u5143\": [\"\u8bbe\u5907\u7ef4\u62a4\u8d39\u7528\", \"\u67f4\u6cb9\u6d88\u8017\u8d39\u7528\"],\n    # \"kWh\": [\"\u7535\u8d1f\u8377\", \"\u4ea7\u7535\u91cf\"],\n}\ndefault_unit_maps = {k: v for v, klist in revmap.items() for k in klist}\n# None -> str\nfrom unit_utils import (\n    unitCleaner,\n    unitParser,\n    standard_units,\n    unitFactorCalculator,\n    ureg,\n    translateUnit,\n)\ndef convert_format(h_array):\n    result_mapping = {}\n    for elem in h_array:\n        # elem = elem.strip()\n        elem = unitCleaner(elem)\n        result = unitParser(elem)\n        if result:\n            elem_name, unit = result[\"val_name\"], result[\"val_unit\"]"
        },
        {
            "comment": "This code is parsing and converting data format for microgrid simulation results. It retrieves headings from the first simulation result, creates a dictionary of common device parameters, updates missing keys in \"\u4eff\u771f\u7ed3\u679c\" with None values, and initializes an empty list for non-countable devices. The code also includes a logger to print information during processing.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":226-258",
            "content": "        else:\n            elem_name = elem\n            unit = default_unit_maps.get(elem, None)\n        if unit:\n            old_unit_name = translateUnit(unit)\n            logger_print(\"processing:\", elem_name)\n            mag, new_unit_name = unitFactorCalculator(\n                ureg, standard_units, old_unit_name\n            )\n            unit = (mag, new_unit_name, old_unit_name)\n        result_mapping[elem_name] = unit\n    return result_mapping\nnew_data[\"\u4eff\u771f\u7ed3\u679c\"][\"ALL\"] = convert_format(data[\"\u4eff\u771f\u7ed3\u679c\"][0][\"headings\"])\nfrom param_base import \u8bbe\u5907\u63a5\u53e3\u96c6\u5408\nall_device_names = list(\u8bbe\u5907\u63a5\u53e3\u96c6\u5408.keys())\nlogger_print()\nlogger_print(all_device_names)\n# \u5916\u90e8\u80fd\u6e90 & \u8d1f\u8377\u7c7b\u578b\nnonDevNames = [\"\u67f4\u6cb9\", \"\u7535\u8d1f\u8377\", \"\u6c22\u8d1f\u8377\", \"\u51b7\u8d1f\u8377\", \"\u70ed\u8d1f\u8377\", \"\u84b8\u6c7d\u8d1f\u8377\", \"\u5e02\u653f\u81ea\u6765\u6c34\", \"\u5929\u7136\u6c14\", \"\u7535\u7f51\", \"\u6c22\u6c14\"]\ncommonDevParams = [\"\u8bbe\u5907\u578b\u53f7\", \"\u8bbe\u5907\u53f0\u6570\", \"\u8bbe\u5907\u7ef4\u62a4\u8d39\u7528\"]\ncommonParams = [\"\u5143\u4ef6\u540d\u79f0\", \"\u5143\u4ef6\u7c7b\u578b\"]\nfor paramName in commonParams:\n    if paramName not in (dictALL := new_data[\"\u4eff\u771f\u7ed3\u679c\"][\"ALL\"]).keys():\n        dictALL.update({paramName: None})\nsimDevParam = {name: [] for name in all_device_names}\nnonCountableDevNames = [\"\u4f20\u8f93\u7ebf\"]"
        },
        {
            "comment": "The code iterates over simulation device parameters, extends them with common parameters and optional additional parameters based on the device type. It then creates a dictionary (simParamLUT) mapping parameter names to lists of devices that use each parameter. All unique simulator parameters are stored in all_sim_params. The setEXC is created by comparing the excel simulation parameters to the simParamLUT keys, and an assertion checks if both sets are equal.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":259-301",
            "content": "for k in simDevParam.keys():\n    simDevParam[k].extend(commonParams)\n    if k not in nonDevNames:\n        simDevParam[k].extend(\n            [\n                e\n                for e in commonDevParams\n                if (e != \"\u8bbe\u5907\u53f0\u6570\" if k in nonCountableDevNames else True)\n            ]\n        )\nsimParamLUT = {\n    \"\u4ea7\u51b7\u91cf\": [],\n    \"\u51b7\u8d1f\u8377\": [],\n    \"\u4ea7\u70ed\u91cf\": [\"\u7535\u89e3\u69fd\", \"\u71c3\u6c14\u53d1\u7535\u673a\"],\n    \"\u70ed\u8d1f\u8377\": [],\n    \"\u4ea7\u7535\u91cf\": [\"\u5149\u4f0f\u53d1\u7535\", \"\u98ce\u529b\u53d1\u7535\", \"\u67f4\u6cb9\u53d1\u7535\", \"\u71c3\u6c14\u53d1\u7535\u673a\"],\n    \"\u7535\u8d1f\u8377\": [\"\u7535\u8d1f\u8377\", \"\u7535\u89e3\u69fd\"],\n    \"\u84b8\u6c7d\u4ea7\u91cf\": [],\n    \"\u84b8\u6c7d\u8d1f\u8377\": [],\n    \"\u6c22\u6c14\u4ea7\u91cf\": [\"\u7535\u89e3\u69fd\"],\n    \"\u6c22\u6c14\u6d88\u8017\u91cf\": [\"\u6c22\u8d1f\u8377\"],\n    \"\u67f4\u6cb9\u6d88\u8017\u91cf\": [\"\u67f4\u6cb9\u53d1\u7535\", \"\u67f4\u6cb9\"],\n    \"\u67f4\u6cb9\u6d88\u8017\u8d39\u7528\": [\"\u67f4\u6cb9\"],\n    \"\u5929\u7136\u6c14\u6d88\u8017\u91cf\": [\"\u71c3\u6c14\u53d1\u7535\u673a\"],\n    \"\u5929\u7136\u6c14\u6d88\u8017\u8d39\u7528\": [],\n    \"\u5e73\u5747\u6548\u7387/\u5e73\u5747COP\": [\"\u67f4\u6cb9\u53d1\u7535\", \"\u4f20\u8f93\u7ebf\", \"\u53d8\u538b\u5668\", \"\u9502\u7535\u6c60\", \"\u53d8\u6d41\u5668\", \"\u53cc\u5411\u53d8\u6d41\u5668\"],\n    \"\u51b7\u6536\u5165\": [],\n    \"\u70ed\u6536\u5165\": [],\n    \"\u7535\u6536\u5165\": [\"\u7535\u8d1f\u8377\"],\n    \"\u84b8\u6c7d\u6536\u5165\": [],\n    \"\u6c22\u6c14\u6536\u5165\": [\"\u6c22\u8d1f\u8377\"],\n    \"\u81ea\u6765\u6c34\u6d88\u8017\u91cf\": [],\n    \"\u81ea\u6765\u6c34\u6d88\u8017\u8d39\u7528\": [],\n}\nall_devs_with_uniq_sim_param = [i for k in simParamLUT.values() for i in k]\nall_sim_params = list(simParamLUT.keys()) + commonDevParams + commonParams\nexcel_sim_params = set(new_data[\"\u4eff\u771f\u7ed3\u679c\"][\"ALL\"].keys())\nassert (setEXC := set(excel_sim_params)) == ("
        },
        {
            "comment": "Iterates through all devices and creates a DataFrame, then writes the table to an Excel file.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":302-335",
            "content": "    setALL := set(all_sim_params)\n), f\"\u53c2\u6570\u4e0d\u7b26\u5408:\\nEXCEL UNIQ: {setEXC.difference(setALL)}\\nCODE UNIQ: {setALL.difference(setEXC)}\"\n# ), f\"\u53c2\u6570\u4e0d\u7b26\u5408:\\nEXCEL UNIQ: {setEXC.difference(setALL)}\\nCODE UNIQ: {setALL.difference(setEXC)}\"\nfor dev in all_device_names:\n    assert dev in all_devs_with_uniq_sim_param, f\"'{dev}'\u6ca1\u6709\u4eff\u771f\u72ec\u6709\u53c2\u6570\"\n# simParamLUT.update({\"\u8bbe\u5907\u7ef4\u62a4\u8d39\u7528\": [d for d in all_device_names if d not in nonDevNames]})\n# simDevParam =\nfor k, vlist in simParamLUT.items():\n    for v in vlist:\n        simDevParam[v].append(k)\ntableRepr = {\n    k: [\n        (\"x\" if k in simDevParam[k1] else \"\") if k != commonParams[0] else k1\n        for k1 in simDevParam.keys()\n    ]\n    for k in sorted(excel_sim_params, key=lambda x: 1 if x != commonParams[0] else 0)\n}\nimport pandas as pd\ndf = pd.DataFrame(tableRepr, index=None)\nlogger_print(df.head())\nfilepath = \"sim_param_export.xlsx\"\nlogger_print(f\"writing to: {filepath}\")\ndf.to_excel(filepath, index=False)\nfor d in all_device_names:\n    # new_data[\"\u4eff\u771f\u7ed3\u679c\"][d] = convert_format(simDevParam[d])"
        },
        {
            "comment": "This code segment is responsible for handling simulation results, parsing data, converting units, and ensuring no duplicate device definitions. It then writes the processed data to a JSON file and passes it along with other parameters to render and format templates.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":336-374",
            "content": "    new_data[\"\u4eff\u771f\u7ed3\u679c\"][d] = {e: new_data[\"\u4eff\u771f\u7ed3\u679c\"][\"ALL\"][e] for e in simDevParam[d]}\n# type? sum or array.\n# unit conversion? divide by conversion rate.\n# in unit conversion exception list? check.\n# matched to which port?\nk = \"\u8bbe\u5907\u51fa\u529b\u66f2\u7ebf\"\nfor elem in data[k]:\n    h, dlist = elem[\"headings\"], elem[\"devices\"]\n    for d in dlist:\n        assert d not in new_data[k].keys(), f\"\u9519\u8bef\uff1a'{d}'\u5728{k}\u4e2d\u91cd\u590d\u5b9a\u4e49\"\n        new_data[k][d] = convert_format(h)\nlogger_print()\nlogger_print(new_data)\nwith open(output_path, \"w+\") as f:\n    f.write(json.dumps(new_data, indent=4, ensure_ascii=False))\nlogger_print(\"write to:\", output_path)\nmodel_names = [f\"{n}\u6a21\u578b\" for n in all_device_names]\nrender_params = dict(\n    main_data=new_data,\n    nonDevNames=nonDevNames,\n    nonCountableDevNames=nonCountableDevNames,\n    \u6bcf\u5e74\u5c0f\u65f6\u6570=\u6bcf\u5e74\u5c0f\u65f6\u6570,\n)\n# render_params = dict(model_names=model_names, main_data=new_data)\nfrom copy import deepcopy\nload_render_and_format(\n    template_path, code_path, deepcopy(render_params), banner=\"FORMAT_VALIDATE_CODE\"\n)\nload_render_and_format(\n    template_unit_path,"
        },
        {
            "comment": "This code is initializing a function call with three parameters: \"code_unit_path\" (path of the code unit), \"render_params\" (deep copied rendering parameters), and \"banner\" set to \"FORMAT_UNIT_CODE\". The purpose seems to be for parsing and formatting code units in the microgrid base.",
            "location": "\"/media/root/Prima/works/generated_docs/linear_programming_doc/src/microgrid_base/parse_export_format.py\":375-378",
            "content": "    code_unit_path,\n    deepcopy(render_params),\n    banner=\"FORMAT_UNIT_CODE\",\n)"
        }
    ]
}