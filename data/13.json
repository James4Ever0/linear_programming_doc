{
    "1300": {
        "file_id": 164,
        "content": "rand = pyimport \"random\"\nval!= rand.choice! 0..10\nprint! val!",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/erglang_test/mytest.er:1-3"
    },
    "1301": {
        "file_id": 164,
        "content": "This code imports the \"random\" library in Python and assigns it to the variable \"rand\". It then generates a random value between 0 and 10 using the \"choice\" function from the \"random\" library, and stores it in the variable \"val\". Finally, it prints the value of \"val\" on the console.",
        "type": "comment"
    },
    "1302": {
        "file_id": 165,
        "content": "/microgrid_base/dsl_parser/erglang_test/sample_external_func.d.er",
        "type": "filepath"
    },
    "1303": {
        "file_id": 165,
        "content": "The code snippet defines an external function in Erlang. It takes a single natural number as input and returns a natural number output.",
        "type": "summary"
    },
    "1304": {
        "file_id": 165,
        "content": ".func!: Nat => Nat",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/erglang_test/sample_external_func.d.er:1-1"
    },
    "1305": {
        "file_id": 165,
        "content": "The code snippet defines an external function in Erlang. It takes a single natural number as input and returns a natural number output.",
        "type": "comment"
    },
    "1306": {
        "file_id": 166,
        "content": "/microgrid_base/dsl_parser/erglang_test/sample_external_func.py",
        "type": "filepath"
    },
    "1307": {
        "file_id": 166,
        "content": "The code defines a lambda function, 'func', which takes an input 'x' and returns the value of 'x+1'.",
        "type": "summary"
    },
    "1308": {
        "file_id": 166,
        "content": "func = lambda x: x+1",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/erglang_test/sample_external_func.py:2-2"
    },
    "1309": {
        "file_id": 166,
        "content": "The code defines a lambda function, 'func', which takes an input 'x' and returns the value of 'x+1'.",
        "type": "comment"
    },
    "1310": {
        "file_id": 167,
        "content": "/microgrid_base/dsl_parser/functional_base.py.j2",
        "type": "filepath"
    },
    "1311": {
        "file_id": 167,
        "content": "This code defines `check_and_append` macro and functions to iterate through a list of statements, execute necessary ones, and append non-executable statements to IES/LES lists while removing elements from LES based on conditions.",
        "type": "summary"
    },
    "1312": {
        "file_id": 167,
        "content": "from typing import List\n{% macro check_and_append(stmt, ies = \"IES\", env = \"environment\") %}\nif check_if_executable({{stmt}}, {{env}}):\n    environment = execute_statement({{stmt}}, {{env}})\n    {{ies}}.append({{stmt}})\n{% endmacro %}\ndef check_if_executable(statement, environment) -> bool:\n    return is_executable\ndef execute_statement(statement, environment):\n    return environment\ndef functional_executor(statement_array:List, \n    environment = ...):\n    IES = []\n    LES = []\n    for statement in statement_array:\n        TLES = [] # create it along the way.\n        # stage 1\n{{check_and_append(\"statement\") | indent(4*2, true)}}\n        else:\n            TLES.append(statement)\n        # stage 2\n        while True:\n            late_removal_indexes = []\n            for index, elem in enumerate(LES.copy()):\n{{check_and_append(\"elem\") | indent(4*4, true)}}\n                    late_removal_indexes.append(index)\n            if len(late_removal_indexes) == 0:\n                break\n            LES = [e for i, e in enumerate(LES) if i not in late_removal_indexes]",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/functional_base.py.j2:1-36"
    },
    "1313": {
        "file_id": 167,
        "content": "This code defines a macro `check_and_append` and functions `check_if_executable`, `execute_statement`, and `functional_executor`. The main function iterates over a list of statements, executes them if necessary, and appends non-executable statements to the `IES` and `LES` lists. It also includes an inner loop that removes elements from the `LES` list based on certain conditions.",
        "type": "comment"
    },
    "1314": {
        "file_id": 167,
        "content": "        # stage 3\n        for elem in TLES:\n{{check_and_append(\"elem\") | indent(4*3, true)}}\n            else:\n                LES.append(elem)\n    # usually, LES == []\n    return IES, LES",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/functional_base.py.j2:38-44"
    },
    "1315": {
        "file_id": 167,
        "content": "This code is iterating through TLES, checking each element, and appending it to LES if it meets certain conditions. If the resulting LES is usually empty, the function returns IES and LES.",
        "type": "comment"
    },
    "1316": {
        "file_id": 168,
        "content": "/microgrid_base/dsl_parser/generate_code.py",
        "type": "filepath"
    },
    "1317": {
        "file_id": 168,
        "content": "This code imports necessary modules, sets the path for code and template files using a utility function, and then loads, renders, and formats the template to generate functional base code.",
        "type": "summary"
    },
    "1318": {
        "file_id": 168,
        "content": "import sys\nsys.path.append(\"../\")\nimport jinja_utils\ncode_path, template_path = jinja_utils.code_and_template_path(\"functional_base\")\njinja_utils.load_render_and_format(\n    template_path, code_path, render_params=dict(), banner=\"FUNCTIONAL BASE CODE\"\n)",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/generate_code.py:1-10"
    },
    "1319": {
        "file_id": 168,
        "content": "This code imports necessary modules, sets the path for code and template files using a utility function, and then loads, renders, and formats the template to generate functional base code.",
        "type": "comment"
    },
    "1320": {
        "file_id": 169,
        "content": "/microgrid_base/dsl_parser/grammar.tx",
        "type": "filepath"
    },
    "1321": {
        "file_id": 169,
        "content": "The code defines a grammar for parsing microgrid input data, including submodels and constants, using keywords and symbols. It introduces ConstantList_Pair, which is a pair of constant lists likely used for defining rules or constraints in the system.",
        "type": "summary"
    },
    "1322": {
        "file_id": 169,
        "content": "Model: modelInfo=ModelInfo subModels+=SubModel;\nSubModel: ConstantLists | Constants;\nModelInfo: '模型名称' BLOCK_SEP modelName=TOKEN;\nConstants: '常量' BLOCK_SEP subConstantBlocks+=subConstantBlock;\nsubConstantBlock: (branch=BRANCHING_KEYWORDS BLOCK_SEP)? constants+=Constant;\nConstant: indicator?=INDICATOR constantName=TOKEN unit?=STRING;\nConstantLists: '常量列表' BLOCK_SEP subConstantListBlocks+=subConstantListBlock;\nsubConstantListBlock: (branch=BRANCHING_KEYWORDS BLOCK_SEP)? constantLists+=CONSTANT_LIST_CANDIDATE;\nCONSTANT_LIST_CANDIDATE: ConstantList | CONSTANTLIST_PAIR ;\nConstantList: indicator?=INDICATOR listName=TOKEN modifier?=MODIFIER unit?=STRING indexRange?=INDEXRANGE;\nINDEXRANGE: ':' '[' ((size=INT) | (index_start=INT ',' index_end=INT (',' index_jump=INT )? ) ) ']';\nTOKEN: !(KEYWORDS BLOCK_SEP) !INDICATOR /[\\w]+/;\nMODIFIER: BOUNDS | CAST;\nBLOCK_SEP: ':' | '：' | '' ;\nBOUND: /[^,^<^>]+/;\nBOUNDS: '<' ((lb=BOUND ',' ub=BOUND) | (lb=BOUND ',' ) | (',' ub=BOUND )) '>';\nCAST: '<' cast=TOKEN '>';\nKEYWORDS: '常量列表' ",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/grammar.tx:1-18"
    },
    "1323": {
        "file_id": 169,
        "content": "This code defines a grammar for parsing input data related to microgrid models, consisting of submodels, constants, constant lists, and other elements. The grammar uses keywords and symbols to recognize different parts of the input data, allowing for structured analysis and extraction of relevant information from the input.",
        "type": "comment"
    },
    "1324": {
        "file_id": 169,
        "content": "        | '常量'\n        | '模型名称';\nINDICATOR:  '<|'\n        | '<<'\n        | '>|'\n        | '>>';\nARITH_0: \"+\" | \"-\";\nARITH_1: \"*\" | \"/\";\nARITH_2: \"^\";\nCOMPARISON: '>=' | '<=' | '>' | '<' | '==';\nINIT_VAL: ':=';\nFUNCTION: 'sum' | 'mean';\nSPECIAL_OPS: '?>' | '??>'\n        | '?<' | '??<'\n        | '|>' | '|<'\n        | '~' | '||';\nConstraints: '约束' BLOCK_SEP subConstantBlocks+=subConstantBlock;\nsubConstraintBlock: (branch=BRANCHING_KEYWORDS BLOCK_SEP)?  constraints+=CONSTRAINT;\nOP: INIT_VAL | COMPARISON;\nCANDIDATE: CONSTRAINT | ELEMENT;\nCONSTRAINT: left=CANDIDATE  op=OP right=CANDIDATE;\nELEMENT: token=TOKEN subscripts*=SUBSCRIPT | special?=SPECIAL_OPS element=ELEMENT | funcName=FUNCTION \"(\" element=ELEMENT \")\";\nSUBSCRIPT_TOKEN: TOKEN (ARITH_0 (TOKEN | INT) )? ;\nSUBSCRIPT: \"[\" subscript=SUBSCRIPT_TOKEN \"]\" ;\nCOMMENT: '#' comment=/.+$/;\nBRANCHING_KEYWORDS: '设计规划' | '仿真模拟' | '秒级仿真' | '日间独立' | '日间连接';\nPIECEWISE: outputVarName=TOKEN '(' inputVarName=TOKEN ')' '~' ( TOKEN | '(' conList_x=ConstantList ',' conList_y=ConstantList ')' ) ;",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/grammar.tx:19-45"
    },
    "1325": {
        "file_id": 169,
        "content": "This code appears to be a grammar definition for a parser, defining tokens and rules for parsing input. It includes keywords, constants, arithmetic operators, comparison operators, initialization, special operations, branching keywords, element types, subscripts, comments, and piecewise functions. The code seems to be specific to a certain application or context related to microgrids or similar systems.",
        "type": "comment"
    },
    "1326": {
        "file_id": 169,
        "content": "CONSTANTLIST_PAIR: pairName=TOKEN '~' '(' conList_x=ConstantList ',' conList_y=ConstantList ')' ;",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/grammar.tx:46-46"
    },
    "1327": {
        "file_id": 169,
        "content": "This code defines a ConstantList_Pair in the grammar. A ConstantList_Pair consists of a pairName, followed by '~', and enclosed in parentheses are two ConstantList instances: conList_x and conList_y. The ConstantList_Pair represents a tuple of constant lists, likely used for defining rules or constraints in the microgrid system.",
        "type": "comment"
    },
    "1328": {
        "file_id": 170,
        "content": "/microgrid_base/dsl_parser/lex_yacc.py",
        "type": "filepath"
    },
    "1329": {
        "file_id": 170,
        "content": "The code defines a LexMeta metaclass that processes class attributes, ensuring token attribute naming consistency and easy identification. It imports PLY lexer and parser modules, builds a sample lexer instance, and creates a parser object from the sampleLex class.",
        "type": "summary"
    },
    "1330": {
        "file_id": 170,
        "content": "class LexMeta(type):\n    def __new__(cls, name, bases, cdict):\n        tokens = []\n        # unprocessed_tokens = []\n        skipped_tokens = []\n        for attrName, attr in cdict.items():\n            # for parser starting with \"p_\"\n            assert not attrName.startswith(\n                \"t_\"\n            ), f\"Wrong attribute name: {attrName}\\nShall not start any attribute with 't_'!\"\n            # if attrName.startswith(\"t_\"):\n            #    unprocessed_tokens.append(attrName)\n            splitedAttrName = list(filter(lambda e: len(e) > 0, attrName.split(\"_\")))\n            if len(splitedAttrName) > 0:\n                indicator = splitedAttrName[-1][0]\n                if indicator.upper() == indicator and indicator.lower() != indicator:\n                    tokens.append(attrName)\n            else:\n                skipped_tokens.append(attrName)\n        cdict[\"tokens\"] = tokens\n        for token in tokens + skipped_tokens:\n            cdict[f\"t_{token}\"] = cdict.pop(token)\n        return super(LexMeta, cls).__new__(cls, name, bases, cdict)",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/lex_yacc.py:1-23"
    },
    "1331": {
        "file_id": 170,
        "content": "This code defines a LexMeta metaclass that processes class attributes, appends \"t_\" to token-related attribute names and stores them as \"t_{token}\", and skips non-token attribute names. The tokens are stored in the 'tokens' attribute of the class. This approach is used for parser starting with \"p_\", ensuring attribute naming consistency and easy identification of token attributes.",
        "type": "comment"
    },
    "1332": {
        "file_id": 170,
        "content": "import ply.lex as lex\nclass sampleLex(metaclass=LexMeta):\n    ID = r\"\\w+\"\n    def build(self, **kwargs):\n        self.lexer = lex.lex(object=self, **kwargs)\nmyLex = sampleLex()\nprint(dir(sampleLex))\nprint(dir(myLex))\nimport ply.yacc as yacc\n# be it a class?\nmyParser = yacc.yacc(module = myModule)",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/lex_yacc.py:26-44"
    },
    "1333": {
        "file_id": 170,
        "content": "This code imports the PLY lexer and parser modules, defines a custom sampleLex class extending LexMeta, and builds a sample lexer instance. It then prints the attributes of the sampleLex class and its instance, before importing the yacc module to create a parser object from the sampleLex class.",
        "type": "comment"
    },
    "1334": {
        "file_id": 171,
        "content": "/microgrid_base/dsl_parser/mylang.ies",
        "type": "filepath"
    },
    "1335": {
        "file_id": 171,
        "content": "This code introduces a microgrid simulation language with variables, constants, and expressions for various modes. It features array operations, bounds checking, automatic differentiation, aggregation of arrays, binary variable operations via broadcasting and multiplication, constant bounds, non-strict symbols in expressions, assertions, and user-defined branches.",
        "type": "summary"
    },
    "1336": {
        "file_id": 171,
        "content": "# highlight dsl with: https://github.com/textX/textX-LS\n# shall you generate typed or type casted code.\n常量: # 常量定义用于检验其是否已经被定义 不得在此处赋值\n    const0\n    const1\n    仿真模拟:\n        simconst\n常量列表：\n实数变量: # 定义变量之前，先检查是否被定义了 如果被定义了 那么就不执行定义操作 例如设备台数\n    <| param0 # 非正\n整数变量：\n    >| param10 # 非负\n    >> param11 # 正数\n变量列表:\n    const_array_pair0 ~ (const_array0 'unit_array_0', const_array1 'unit_array_1') # packing 1d array of same shape into 2d array\n非负变量列表:\n    param1\n    param2\n    param11: [100] # size of 100, index from 0 to 99\n    param5<0,100>: [1,10] # varName<lb, ub>'unit specification': [index_start, index_end, [index_jump]], if variables has been passed to bounds, automatically calculate constant lb/ub for it, then add actual constraints\n    param8\n二元变量列表:\n    param12: [11]\n    bin_param10 <param10>  # like ~param10\n指示变量列表: #不能直接使用\n    param3 <param8>  # assignment symbol (<>): define relaionship between indicators and variables/expressions.\n单指示变量:\n    param7 <param10>\n分段函数：\n    param9(param8) ~ (const_array0, const_array1)",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/mylang.ies:1-30"
    },
    "1337": {
        "file_id": 171,
        "content": "Code defines various variable types, constants, and lists for a model. It includes constants like const0 and const1, simulation variables like simconst, and different types of variables such as real, integer, and binary variables. The code also includes non-negative variables, parameters, and section functions for the model.",
        "type": "comment"
    },
    "1338": {
        "file_id": 171,
        "content": "    param12(param11) ~ const_array_pair0 # input must be const/var 1d array, output with same type\n约束: # 不同的计算模式需要添加不同的约束 这里定义公共约束\n    秒级仿真:\n        ...\n    设计规划:\n        planningConstraint\n    仿真模拟:\n        simulationConstraint\n    param6 = param1 + param2 # intermediate expression list. type: list[expr]\n    param1 < param0 \n    param1 < 10 # constant bounds are recorded and compared.\n    param1 + param2 < param0\n    param1[i] + param2[i+1] < param0, (optional syntax): [0, maxIndex]\n    param1[i] + param2[i+j] < param0: i = -1, j = [1,10]\n    diff(param1) = param0 # diff(param1) = (param[i] - param[i+1]) * timeparam 自动微分 默认是时间微分\n    param3 # meaning: param3.x\n    (param3) # deprecated.\n    mean(param3) # shall complain when passed in some non-list objects. but mean(param3+1) won't complain.\n    sum(param3)\n    |> param3\n    |< param3\n    ~param10 # meaning: break down a single integer variable into multiple decision (binary) variables, bin_param10, with constraint param10_lb <= sum(bin_param10) <= param10",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/mylang.ies:31-52"
    },
    "1339": {
        "file_id": 171,
        "content": "This code defines a language for microgrid simulation, with constraints and expressions for different simulation modes. It includes functions for array operations, bounds checking, automatic differentiation, and aggregation operations on arrays. The syntax is also defined with optional indexing and deprecated notation.",
        "type": "comment"
    },
    "1340": {
        "file_id": 171,
        "content": ", len(bin_param10) == param_10_ub, sum(bin_param10) == param10, and will broadcast this to all variables & varlist, by expanding into another dimension with size of param_10_ub. the lower bound and upper bound of param_10 must be constants. e.g. p0[i][j] < bp[j] * p1[i][j], which i is time index, all other indexs (j,k,l) are discrete indexs.\n    ?>param3 # type: binary variable list.\n    ?<param2 # when putting variable list like \"param2\", create or find indicator variable list along the way, then do the operation.\n    ??>param3 # check if it is \"really\" positive, equivalent to: ?>(param3 - EPS), EPS = 1e-5. when used with integer variables (list), automatically use this form instead.\n    ??<param3\n    ||param3\n    param3 * param4 # linearization needed! need param3 and param4 to be bounded. if unsure about its minima and maxima, then do not use it in other non-linear expression.\n    param3 < param4 <= param5 # separate this into two expressions. check all symbols are of inequality or equalit",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/mylang.ies:52-59"
    },
    "1341": {
        "file_id": 171,
        "content": "The code defines operations for a binary variable list (param3) and uses various operators such as broadcasting, equality checks, and multiplication. It also mentions the importance of ensuring bounds are constants and warns about linearization needs when using bound variables in non-linear expressions.",
        "type": "comment"
    },
    "1342": {
        "file_id": 171,
        "content": "y (=) and with same directions. enforce all symbols in expressions (with variables) are non-strict (>= <=) by automatic conversion.\n    const0 > const1 # make this into assertion, do not convert symbol in any way.\n    param3[0] := 1 # init val.\n    param3 := 0 # init all. val must be constant. execution order preserved.\n    USER_DEFINED_BRANCH: # this branch must be defined somewhere, by reading some config file.\n        branched_constraint",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/mylang.ies:59-64"
    },
    "1343": {
        "file_id": 171,
        "content": "This code initializes and configures symbols in expressions to be non-strict (>= <=) and sets up an assertion for constant comparison. It also initializes a parameter value, ensures all symbols are non-strict, and defines a user-defined branch using a branched constraint.",
        "type": "comment"
    },
    "1344": {
        "file_id": 172,
        "content": "/microgrid_base/dsl_parser/pyomo_reduce_inequalities.py",
        "type": "filepath"
    },
    "1345": {
        "file_id": 172,
        "content": "The code uses Pyomo and CPLEX to create a mathematical model with variables, constraints, and solves it, checking for abnormal exit conditions and printing x bounds.",
        "type": "summary"
    },
    "1346": {
        "file_id": 172,
        "content": "# from sympy import symbols\n# TODO: create more readable constraint names for easy debugging\n# TODO: extract infeasible constraints with relevant solver message\n# use pyomo\nfrom pyomo.environ import *\nx_bounds = []\nfor sense in [minimize, maximize]:\n    model = ConcreteModel()\n    x = model.变量x = Var()\n    y = model.变量y = Var()\n    z = model.变量z = Var()\n    h = model.变量h = Var()\n    # z = model.z = Var()\n    # x, y, z = symbols(\"x y z\")\n    # infeasible on y.\n    # unbounded\n    # expressions = [y >= z, y <= 20, y >= 10, z <= 0, z >= -10, x <= 100 - y]\n    # feasible\n    # expressions = [y >= z, y <= 20, y >= 10, z <= 0, z >= -10, x <= 100 - y, x >= y - z]\n    # infeasible\n    # expressions = [y >= z, y >= 20, y <= 10, z <= 0, z >= -10, x <= 100 - y, x >= y - z]\n    # double infeasible (will not show both)\n    expressions = [y >= z, y >= 20, y <= 10, h >= 20, h <= 10, z <= 0, z >= -10, x <= 100 - (h+y)/2, x >= (h+y)/2 - z]\n    # Bound infeasibility column '变量y'.\n    # check if is unbounded or infeasible.\n    # try to comment that out, see if it can solve",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/pyomo_reduce_inequalities.py:1-30"
    },
    "1347": {
        "file_id": 172,
        "content": "This code uses Pyomo to create a mathematical model with variables x, y, z, and h. It defines constraints based on different scenarios of feasibility and infeasibility for the variable y. The expressions define the relationships between these variables, and the code checks if the model is unbounded or infeasible.",
        "type": "comment"
    },
    "1348": {
        "file_id": 172,
        "content": "    # red = reduce_inequalities(expresssions, [x])\n    for i, _expr in enumerate(expressions):\n        model.__setattr__(f\"expr_{i}\", Constraint(expr=_expr))\n    # print(red)\n    obj = model.obj = Objective(expr=x, sense=sense)\n    io_options = dict(symbolic_solver_labels=True)\n    model.write(filename=\"your_model_name.lp\", io_options=io_options)\n    solver = SolverFactory(\"cplex\")\n    # 求解器变量乱码,影响求解\n    solver.options[\"read fileencoding\"] = 'utf-8'\n    # TODO: get solver log.\n    result = solver.solve(model, tee=True, io_options=io_options)\n    TC = result.solver.termination_condition\n    import rich\n    rich.print(result)\n    normalTCs = [\n        TerminationCondition.globallyOptimal,\n        TerminationCondition.locallyOptimal,\n        TerminationCondition.feasible,\n        TerminationCondition.optimal,\n    ]\n    if TC == TerminationCondition.infeasible:\n        raise Exception(\"infeasible constraint found. please check expression\")\n    elif TC == TerminationCondition.unbounded:\n        raise Exception(\"unbounded constraint found. please check expression\")",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/pyomo_reduce_inequalities.py:31-57"
    },
    "1349": {
        "file_id": 172,
        "content": "Code sets up a model, writes it to file, solves with CPLEX solver, and handles potential exceptions for infeasible or unbounded constraints.",
        "type": "comment"
    },
    "1350": {
        "file_id": 172,
        "content": "    elif TC not in normalTCs:\n        raise Exception(f\"abnormal solver exit condition: {TC}\")\n    print(\"val? %s, sense? %s\" % (val_x := value(x), sense))\n    x_bounds.append(val_x)\nprint(\"x bounds:\", x_bounds)",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/pyomo_reduce_inequalities.py:58-63"
    },
    "1351": {
        "file_id": 172,
        "content": "This code checks if the solver exit condition is abnormal and raises an exception with the details. It also prints the value of variable x, its sense (equal to or greater than), adds the value to a list of bounds, and finally prints the complete list of x bounds.",
        "type": "comment"
    },
    "1352": {
        "file_id": 173,
        "content": "/microgrid_base/dsl_parser/sample.ies",
        "type": "filepath"
    },
    "1353": {
        "file_id": 173,
        "content": "This code appears to be written in Chinese. It seems to define a model named \"abcd\" and includes several constants (a, b, C) and a constant list (d, e).",
        "type": "summary"
    },
    "1354": {
        "file_id": 173,
        "content": "模型名称\n    abcd\n常量\n    a\n    <| b\n    >> C\n常量列表\n    >> d\n    >> e",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/sample.ies:1-9"
    },
    "1355": {
        "file_id": 173,
        "content": "This code appears to be written in Chinese. It seems to define a model named \"abcd\" and includes several constants (a, b, C) and a constant list (d, e).",
        "type": "comment"
    },
    "1356": {
        "file_id": 174,
        "content": "/microgrid_base/dsl_parser/suppress_strict_inequalities.py",
        "type": "filepath"
    },
    "1357": {
        "file_id": 174,
        "content": "The code defines a function build_and_solve_model_with_strict_inequality, which creates a Pyomo model with constraints and an objective, solves it using CPLEX solver, and prints the result. It also includes a patch to suppress strict inequality in Pyomo expressions.",
        "type": "summary"
    },
    "1358": {
        "file_id": 174,
        "content": "from pyomo.environ import *\nimport rich\ndef build_and_solve_model_with_strict_inequality():\n    model = ConcreteModel()\n    model.x = Var(bounds=(-1,1))\n    model.y = Var(bounds=(-1,1))\n    model.rel = Constraint(expr=model.x < model.y) # error, if not patched.\n    model.obj = Objective(expr=model.x, sense=minimize)\n    solver = SolverFactory('cplex')\n    ret = solver.solve(model, tee=True)\n    rich.print(ret)\n# build_and_solve_model_with_strict_inequality()\n# print(\"#\"*60)\n######## SUPPRESS STRICT INEQUALITY PATCH #########\ndef strict_setter(self, val):\n    ...\ndef strict_getter(self):\n    return False\nInEq = pyomo.core.expr.relational_expr.InequalityExpression\nsetattr(InEq,\"_strict_setter\", strict_setter)\nsetattr(InEq,\"_strict_getter\", strict_getter)\nInEq._strict = property(fget=InEq._strict_getter, fset=InEq._strict_setter)\nInEq.strict = InEq._strict\n######## SUPPRESS STRICT INEQUALITY PATCH #########\nbuild_and_solve_model_with_strict_inequality()",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/suppress_strict_inequalities.py:1-35"
    },
    "1359": {
        "file_id": 174,
        "content": "The code defines a function build_and_solve_model_with_strict_inequality, which creates a Pyomo model with constraints and an objective, solves it using CPLEX solver, and prints the result. It also includes a patch to suppress strict inequality in Pyomo expressions.",
        "type": "comment"
    },
    "1360": {
        "file_id": 175,
        "content": "/microgrid_base/dsl_parser/test/test_dsl.py",
        "type": "filepath"
    },
    "1361": {
        "file_id": 175,
        "content": "This code retrieves DSL files and ensures corresponding JSON files, defines fixtures for a test suite using TextX to parse sample code with specified grammar, and tests the parsing functionality.",
        "type": "summary"
    },
    "1362": {
        "file_id": 175,
        "content": "from pytest import fixture, FixtureRequest\nimport os\nimport json\nimport sys\nsys.path.append(\"../\")\nfrom ast_utils import walkModel\nsample_code_dir = \"sample_code\"\npath_to_mark = lambda path: os.path.basename(path).split(\".\")[0]\nsample_code_paths = [\n    os.path.join(sample_code_dir, code_path)\n    for code_path in os.listdir(sample_code_dir)\n    if code_path.endswith(\".dsl\")\n]\nsample_code_parsed_paths = [\n    os.path.join(sample_code_dir, code_parsed_paths)\n    for code_parsed_paths in os.listdir(sample_code_dir)\n    if code_parsed_paths.endswith(\".json\")\n]\nsample_code_marks = [\n    os.path.basename(rel_code_path).split(\".\")[0] for rel_code_path in sample_code_paths\n]\n# check if all code has parsed output\nfor mark in sample_code_marks:\n    assert (\n        os.path.join(sample_code_dir, mark + \".json\") in sample_code_parsed_paths\n    ), f\"Missing parsed output: {mark}\"\nsample_code_parsed_paths_dict = {path_to_mark(p): p for p in sample_code_parsed_paths}\nsample_code_paths_dict = {path_to_mark(p): p for p in sample_code_paths}",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/test/test_dsl.py:1-36"
    },
    "1363": {
        "file_id": 175,
        "content": "The code retrieves all DSL files from a directory and ensures that there is a corresponding JSON file for each DSL file. It creates dictionaries of the DSL paths and parsed output paths based on their respective marks. This code seems to be part of a test suite, likely testing the functionality of parsing DSLs into JSON outputs.",
        "type": "comment"
    },
    "1364": {
        "file_id": 175,
        "content": "from collections import namedtuple\nCPJ = namedtuple(\"CPJ\", [\"code\", \"parsed_json\"])\nimport textx\n@fixture\ndef metamodel():\n    grammar_path = \"../grammar.tx\"\n    with open(grammar_path, \"r\") as f:\n        grammar_content = f.read()\n    mm = textx.metamodel_from_str(grammar_content)\n    return mm\n@fixture(params=sample_code_marks)\ndef sample_code(request: FixtureRequest):\n    mark = request.param\n    code_path = sample_code_paths_dict[mark]\n    parsed_path = sample_code_parsed_paths_dict[mark]\n    print(\"READING CODE AT:\", code_path)\n    with open(code_path, \"r\") as f:\n        code_content = f.read()\n    with open(parsed_path, \"r\") as f:\n        parsed_content = f.read()\n        parsed_json = json.loads(parsed_content)\n    return CPJ(code=code_content, parsed_json=parsed_json)\nfrom textx.metamodel import TextXMetaModel\ndef test_parse_code(sample_code: CPJ, metamodel: TextXMetaModel):\n    model = metamodel.model_from_str(sample_code.code)\n    tree = walkModel(model)\n    target_tree = sample_code.parsed_json\n    assert tree == target_tree",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/test/test_dsl.py:38-75"
    },
    "1365": {
        "file_id": 175,
        "content": "This code defines fixtures for a test suite and uses TextX to parse sample code according to the specified grammar. The `metamodel` fixture loads the grammar from a file, while the `sample_code` fixture reads both the original code and its expected parsed result from separate files given by the `sample_code_marks`. The `test_parse_code` function uses the loaded metamodel to parse a sample of code and asserts that the resulting model matches the expected parsed JSON.",
        "type": "comment"
    },
    "1366": {
        "file_id": 176,
        "content": "/microgrid_base/dsl_parser/textx_syntax.py",
        "type": "filepath"
    },
    "1367": {
        "file_id": 176,
        "content": "Code reads a grammar file, constructs a metamodel from it, and parses an input file to create a model using that metamodel. Then, it prints the structure of the parsed model and accesses specific elements like constants and constant lists in submodels. It uses 'rich' library for printing formatted output.",
        "type": "summary"
    },
    "1368": {
        "file_id": 176,
        "content": "import textx\n# TODO: perform unittest on serialized AST\n# STRING is something quoted. not plain words.\n# define and use TOKEN or VARNAME instead.\n# shall you name collected items to retrieve them.\nwith open(\"grammar.tx\", \"r\") as f:\n    grammar = f.read()\nmetamodel = textx.metamodel_from_str(grammar)\nwith open(fp := \"sample.ies\", \"r\") as f:\n    content = f.read()\nfrom ast_utils import walkModel\nmodel = metamodel.model_from_str(content)\n# print(dir(model))\n# breakpoint()\nimport rich\ntree = walkModel(model)\nrich.print(tree)\nbreakpoint()\ncn = lambda i: i.__class__.__name__\nprint(model.modelInfo)\nfor subModel in model.subModels:\n    print(subModel)\n    if cn(subModel) == \"Constants\":\n        print(subModel.constants)\n    elif cn(subModel) == \"ConstantLists\":\n        print(subModel.constantLists)\n# import rich\n# rich.print(model.__dict__)\n# breakpoint()",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/textx_syntax.py:1-38"
    },
    "1369": {
        "file_id": 176,
        "content": "Code reads a grammar file, constructs a metamodel from it, and parses an input file to create a model using that metamodel. Then, it prints the structure of the parsed model and accesses specific elements like constants and constant lists in submodels. It uses 'rich' library for printing formatted output.",
        "type": "comment"
    },
    "1370": {
        "file_id": 177,
        "content": "/microgrid_base/dsl_parser/yacc_init.py",
        "type": "filepath"
    },
    "1371": {
        "file_id": 177,
        "content": "The code imports the `ply.lex` and `ply.yacc` modules for lexical analysis and parsing, respectively. It then creates instances of these classes (`lex` and `yacc`) to perform lexical analysis and parsing on input data.",
        "type": "summary"
    },
    "1372": {
        "file_id": 177,
        "content": "import ply.lex\nimport ply.yacc\n# construct definition within class created by metaclass, or templates\nlex = ply.lex.lex()\nyacc = ply.yacc.yacc()",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/yacc_init.py:1-6"
    },
    "1373": {
        "file_id": 177,
        "content": "The code imports the `ply.lex` and `ply.yacc` modules for lexical analysis and parsing, respectively. It then creates instances of these classes (`lex` and `yacc`) to perform lexical analysis and parsing on input data.",
        "type": "comment"
    },
    "1374": {
        "file_id": 178,
        "content": "/microgrid_base/dsl_parser/your_model_name.lp",
        "type": "filepath"
    },
    "1375": {
        "file_id": 178,
        "content": "This code represents a Pyomo model for an optimization problem. The objective is to minimize the variable 'x'. The constraints involve variables 'y', 'z', and 'h' with specific bounds. Variables 'y' and 'z' are further constrained by upper and lower limits, while variable 'h' has both upper and lower bounds. There's also a constant defined as ONE_VAR_CONSTANT=1.0, and all variables have unbounded lower and upper limits.",
        "type": "summary"
    },
    "1376": {
        "file_id": 178,
        "content": "\\* Source Pyomo model name=unknown *\\\nmin \nobj:\n+1 变量x\ns.t.\nc_u_expr_0_:\n-1 变量y\n+1 变量z\n<= 0\nc_l_expr_1_:\n+1 变量y\n>= 20\nc_u_expr_2_:\n+1 变量y\n<= 10\nc_l_expr_3_:\n+1 变量h\n>= 20\nc_u_expr_4_:\n+1 变量h\n<= 10\nc_u_expr_5_:\n+1 变量z\n<= 0\nc_l_expr_6_:\n+1 变量z\n>= -10\nc_u_expr_7_:\n+0.5 变量h\n+1 变量x\n+0.5 变量y\n<= 100\nc_u_expr_8_:\n+0.5 变量h\n-1 变量x\n+0.5 变量y\n-1 变量z\n<= 0\nc_e_ONE_VAR_CONSTANT: \nONE_VAR_CONSTANT = 1.0\nbounds\n    -inf <= 变量x <= +inf\n    -inf <= 变量y <= +inf\n    -inf <= 变量z <= +inf\n    -inf <= 变量h <= +inf\nend",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/your_model_name.lp:1-59"
    },
    "1377": {
        "file_id": 178,
        "content": "This code represents a Pyomo model for an optimization problem. The objective is to minimize the variable 'x'. The constraints involve variables 'y', 'z', and 'h' with specific bounds. Variables 'y' and 'z' are further constrained by upper and lower limits, while variable 'h' has both upper and lower bounds. There's also a constant defined as ONE_VAR_CONSTANT=1.0, and all variables have unbounded lower and upper limits.",
        "type": "comment"
    },
    "1378": {
        "file_id": 179,
        "content": "/microgrid_base/dsl_parser/柴油.ies",
        "type": "filepath"
    },
    "1379": {
        "file_id": 179,
        "content": "This code describes a fuel model called \"柴油模型\" with constants like Price, thermal value (MJ/L), CO2, NOX, and SO2. It lists inputs such as fuel interfaces and constraints including average consumption rate, annual cost, and total cost yearly.",
        "type": "summary"
    },
    "1380": {
        "file_id": 179,
        "content": "模型名称：\n    柴油模型\n常量：\n    Price\n    热值 (MJ/L) # if bracket is ahead of any symbols (not function name!), treat it content as unit specification\n    CO2 (kg/L) # unit annotation shall not be shown more than once.\n    NOX \"kg/L\" # provide unit inference to unannotated symbols. default unit to any unannotated symbol is \"one\"\n    SO2 (kg/L)\n变量列表：\n    >| 燃料接口\n约束:\n    平均消耗率 = avg(燃料接口) # or: average\n    年化费用 (万元/年) = 平均消耗率 * Price * 每年小时数 # global constant: 8760\n    # this shall be unit conversion problem, like: dollar/hour -> dollar/year\n    总成本年化 = 年化费用",
        "type": "code",
        "location": "/microgrid_base/dsl_parser/柴油.ies:1-15"
    },
    "1381": {
        "file_id": 179,
        "content": "This code describes a fuel model called \"柴油模型\" with constants like Price, thermal value (MJ/L), CO2, NOX, and SO2. It lists inputs such as fuel interfaces and constraints including average consumption rate, annual cost, and total cost yearly.",
        "type": "comment"
    },
    "1382": {
        "file_id": 180,
        "content": "/microgrid_base/enum_class_as_literal_type.py",
        "type": "filepath"
    },
    "1383": {
        "file_id": 180,
        "content": "This code demonstrates the usage of Enum, Literal, and Pydantic to define constants, enforce type checking, and validate input data. It defines an enumeration class \"a\" with values RED, GREEN, BLUE, and creates a Pydantic model \"A\" with an attribute \"a0\" that must be one of the enum values. The code performs type checks, asserts, and validations while logging output for debugging purposes.",
        "type": "summary"
    },
    "1384": {
        "file_id": 180,
        "content": "from log_utils import logger_print\n# from enum import StrEnum\n# a = StrEnum('Color', ['RED', 'GREEN', 'BLUE'])\nfrom enum import Enum\n# a = Enum('Color', ['RED', 'GREEN', 'BLUE'])\nfrom typing import Literal\nl: Literal[\"a\", \"b\"] = \"b\"\nif isinstance(l, \"c\"):\n    logger_print(\"never executed\")\nclass a(Enum):\n    RED = \"red\"\n    GREEN = \"green\"\n    BLUE = \"blue\"\nb: a = a.BLUE  # Color.BLUE\nlogger_print(b, type(b))\n# will be converted into lower case.\n# assert (b == 'blue2') # false\nassert b == \"blue\"  # true\nif b == a.GREEN:\n    logger_print(\"NEVER EXECUTE\")\nfrom pydantic import BaseModel\nclass A(BaseModel):\n    a0: a\ndata = A(a0=\"blue\")  # though static type error, still working\n# data = A(a0 = \"blue2\") # validation error.\n# data = A(a0 = a['BLUE']) # working\nlogger_print(\"data\", data, data.a0)",
        "type": "code",
        "location": "/microgrid_base/enum_class_as_literal_type.py:1-40"
    },
    "1385": {
        "file_id": 180,
        "content": "This code demonstrates the usage of Enum, Literal, and Pydantic to define constants, enforce type checking, and validate input data. It defines an enumeration class \"a\" with values RED, GREEN, BLUE, and creates a Pydantic model \"A\" with an attribute \"a0\" that must be one of the enum values. The code performs type checks, asserts, and validations while logging output for debugging purposes.",
        "type": "comment"
    },
    "1386": {
        "file_id": 181,
        "content": "/microgrid_base/enumerate_possible_states.py",
        "type": "filepath"
    },
    "1387": {
        "file_id": 181,
        "content": "The `get_all_combinations` function generates all possible state combinations and checks conditions before adding them to the result list, returning the final list of all states.",
        "type": "summary"
    },
    "1388": {
        "file_id": 181,
        "content": "from log_utils import logger_print\nimport itertools\ndef get_all_combinations(\n    portNameToPortPossibleStates, energyTypeToPortNames, adderNameToAdderPortNames\n):\n    port_name_to_possible_energy_types = {}\n    for k, vlist in energyTypeToPortNames.items():\n        for v in vlist:\n            if v not in port_name_to_possible_energy_types.keys():\n                port_name_to_possible_energy_types[v] = [k]\n            port_name_to_possible_energy_types[v].append(k)\n    adder_name_list = list(adderNameToAdderPortNames.keys())\n    possible_simutaneous_adder_energy_types = set()\n    adder_name_to_possible_adder_energy_types = {}\n    for adder_name, _port_name_list in adderNameToAdderPortNames.items():\n        paet = set()\n        for pn in _port_name_list:\n            ets = port_name_to_possible_energy_types[pn]\n            paet.update(ets)\n        adder_name_to_possible_adder_energy_types[adder_name] = paet\n    possible_simutaneous_adder_energy_types = []\n    possible_simutaneous_adder_energy_types = list(\n        itertools.product(*adder_name_to_possible_adder_energy_types.values())",
        "type": "code",
        "location": "/microgrid_base/enumerate_possible_states.py:1-33"
    },
    "1389": {
        "file_id": 181,
        "content": "Function `get_all_combinations` retrieves all possible state combinations. It utilizes a dictionary to store port energy types and another for simultaneous adder energy types, then generates these combinations using itertools.product.",
        "type": "comment"
    },
    "1390": {
        "file_id": 181,
        "content": "    )\n    result = []\n    # get `possible_adder_energy_types` from prolog?\n    for simutaneous_adder_energy_types in possible_simutaneous_adder_energy_types:\n        simutaneous_state = []\n        # all idle, otherwise at least one input one output\n        aet_to_ps_l = []\n        for adder_index, aet in enumerate(simutaneous_adder_energy_types):\n            sasp = []\n            adder_name = adder_name_list[adder_index]\n            _port_name_list = adderNameToAdderPortNames[adder_name]\n            psl = []\n            for pn in _port_name_list:\n                ppet = port_name_to_possible_energy_types[pn]\n                pps = portNameToPortPossibleStates[pn]\n                if aet in ppet:\n                    ps = pps\n                else:\n                    assert \"idle\" in pps\n                    ps = [\"idle\"]\n                psl.append(ps)\n            for elem in itertools.product(*psl):\n                if all([e == \"idle\" for e in elem]) or (\n                    \"input\" in elem and \"output\" in elem\n                ):",
        "type": "code",
        "location": "/microgrid_base/enumerate_possible_states.py:34-60"
    },
    "1391": {
        "file_id": 181,
        "content": "This code is iterating over possible combinations of energy types for different adder devices in a microgrid. It checks if any combination has all devices idle or at least one device with input and output states, then adds it to the result list. The possible energy types are retrieved from some prolog data.",
        "type": "comment"
    },
    "1392": {
        "file_id": 181,
        "content": "                    sasp.append([aet, elem])\n            aet_to_ps_l.append(sasp)\n        for elem in itertools.product(*aet_to_ps_l):\n            simutaneous_state.append(elem)\n        result.extend(simutaneous_state)\n    return result",
        "type": "code",
        "location": "/microgrid_base/enumerate_possible_states.py:61-67"
    },
    "1393": {
        "file_id": 181,
        "content": "The code generates all possible combinations of state elements for each area-element tuple, appends them to a list, and extends the result list. Finally, it returns the resulting list containing all possible states.",
        "type": "comment"
    },
    "1394": {
        "file_id": 182,
        "content": "/microgrid_base/export_format_units.py",
        "type": "filepath"
    },
    "1395": {
        "file_id": 182,
        "content": "The code defines classes representing energy sources and devices, each specifying export units for various measurements used in microgrid simulations or analysis systems. Variables include device count, maintenance cost, heat production, electrical load, hydrogen gas output, all measured in their respective units (kWh or t).",
        "type": "summary"
    },
    "1396": {
        "file_id": 182,
        "content": "from log_utils import logger_print\nclass 柴油仿真结果导出单位:\n    柴油消耗量 = \"L\"\n    柴油消耗费用 = \"万元\"\nclass 电负荷仿真结果导出单位:\n    电负荷 = \"kWh\"\n    电收入 = \"万元\"\nclass 光伏发电仿真结果导出单位:\n    设备台数 = \"one\"\n    设备维护费用 = \"万元\"\n    产电量 = \"kWh\"\nclass 风力发电仿真结果导出单位:\n    设备台数 = \"one\"\n    设备维护费用 = \"万元\"\n    产电量 = \"kWh\"\nclass 柴油发电仿真结果导出单位:\n    设备台数 = \"one\"\n    设备维护费用 = \"万元\"\n    产电量 = \"kWh\"\n    柴油消耗量 = \"L\"\n    平均效率_平均COP = \"one\"\nclass 锂电池仿真结果导出单位:\n    设备台数 = \"one\"\n    设备维护费用 = \"万元\"\n    平均效率_平均COP = \"one\"\nclass 变压器仿真结果导出单位:\n    设备台数 = \"one\"\n    设备维护费用 = \"万元\"\n    平均效率_平均COP = \"one\"\nclass 变流器仿真结果导出单位:\n    设备台数 = \"one\"\n    设备维护费用 = \"万元\"\n    平均效率_平均COP = \"one\"\nclass 双向变流器仿真结果导出单位:\n    设备台数 = \"one\"\n    设备维护费用 = \"万元\"\n    平均效率_平均COP = \"one\"\nclass 传输线仿真结果导出单位:\n    设备维护费用 = \"万元\"\n    平均效率_平均COP = \"one\"\nclass 氢负荷仿真结果导出单位:\n    氢气消耗量 = \"t\"\n    氢气收入 = \"万元\"\nclass 燃气发电机仿真结果导出单位:\n    设备台数 = \"one\"\n    设备维护费用 = \"万元\"\n    产热量 = \"kWh\"\n    产电量 = \"kWh\"\n    天然气消耗量 = \"m3\"\nclass 电解槽仿真结果导出单位:",
        "type": "code",
        "location": "/microgrid_base/export_format_units.py:1-76"
    },
    "1397": {
        "file_id": 182,
        "content": "This code defines various classes representing different types of energy sources and devices. Each class specifies the export units for various measurements such as power, fuel consumption, maintenance costs, etc., which are likely used in the context of a microgrid simulation or analysis system.",
        "type": "comment"
    },
    "1398": {
        "file_id": 182,
        "content": "    设备台数 = \"one\"\n    设备维护费用 = \"万元\"\n    产热量 = \"kWh\"\n    电负荷 = \"kWh\"\n    氢气产量 = \"t\"",
        "type": "code",
        "location": "/microgrid_base/export_format_units.py:77-81"
    },
    "1399": {
        "file_id": 182,
        "content": "The code defines variables for device count, maintenance cost, heat production, electrical load, and hydrogen gas output, all measured in their respective units (kWh or t).",
        "type": "comment"
    }
}